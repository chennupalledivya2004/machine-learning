{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b40e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_759</th>\n",
       "      <th>embed_760</th>\n",
       "      <th>embed_761</th>\n",
       "      <th>embed_762</th>\n",
       "      <th>embed_763</th>\n",
       "      <th>embed_764</th>\n",
       "      <th>embed_765</th>\n",
       "      <th>embed_766</th>\n",
       "      <th>embed_767</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009625</td>\n",
       "      <td>-0.029216</td>\n",
       "      <td>0.027109</td>\n",
       "      <td>0.023631</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>-0.045125</td>\n",
       "      <td>0.044483</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>-0.008154</td>\n",
       "      <td>-0.056139</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.042366</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>-0.016137</td>\n",
       "      <td>-0.009309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007535</td>\n",
       "      <td>-0.039844</td>\n",
       "      <td>0.030167</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.028289</td>\n",
       "      <td>-0.068723</td>\n",
       "      <td>0.039153</td>\n",
       "      <td>0.019596</td>\n",
       "      <td>-0.027138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>-0.006578</td>\n",
       "      <td>-0.034220</td>\n",
       "      <td>0.027574</td>\n",
       "      <td>0.045456</td>\n",
       "      <td>0.027402</td>\n",
       "      <td>0.017837</td>\n",
       "      <td>-0.035009</td>\n",
       "      <td>-0.010062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022408</td>\n",
       "      <td>-0.030840</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>0.046965</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>-0.065093</td>\n",
       "      <td>0.035118</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>-0.029205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>-0.034288</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>0.028408</td>\n",
       "      <td>0.040412</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>-0.034122</td>\n",
       "      <td>-0.017289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019677</td>\n",
       "      <td>-0.034055</td>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.070387</td>\n",
       "      <td>-0.011170</td>\n",
       "      <td>0.017842</td>\n",
       "      <td>-0.050945</td>\n",
       "      <td>0.044878</td>\n",
       "      <td>0.034781</td>\n",
       "      <td>-0.025772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>-0.018754</td>\n",
       "      <td>-0.053278</td>\n",
       "      <td>0.033005</td>\n",
       "      <td>0.031635</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>-0.011774</td>\n",
       "      <td>-0.011125</td>\n",
       "      <td>-0.017540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017678</td>\n",
       "      <td>-0.030323</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.065267</td>\n",
       "      <td>-0.025161</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>-0.050590</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>-0.015004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>-0.010147</td>\n",
       "      <td>-0.035857</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>0.034621</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>-0.009884</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>-0.029238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.019743</td>\n",
       "      <td>-0.071799</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.049042</td>\n",
       "      <td>-0.005767</td>\n",
       "      <td>-0.016275</td>\n",
       "      <td>-0.037731</td>\n",
       "      <td>0.029718</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>-0.030913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001192</td>\n",
       "      <td>-0.026138</td>\n",
       "      <td>-0.056447</td>\n",
       "      <td>0.015818</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>-0.004837</td>\n",
       "      <td>-0.014540</td>\n",
       "      <td>-0.046791</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.027604</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>-0.026675</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>-0.040816</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>-0.037808</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>-0.010890</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>-0.015145</td>\n",
       "      <td>-0.045444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.018066</td>\n",
       "      <td>-0.032152</td>\n",
       "      <td>0.039794</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.024092</td>\n",
       "      <td>-0.056508</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>0.031972</td>\n",
       "      <td>-0.026038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>-0.016882</td>\n",
       "      <td>-0.059904</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.039976</td>\n",
       "      <td>0.029574</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>-0.003724</td>\n",
       "      <td>-0.017324</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-0.003492</td>\n",
       "      <td>-0.022739</td>\n",
       "      <td>0.021777</td>\n",
       "      <td>0.044054</td>\n",
       "      <td>-0.005621</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>-0.079196</td>\n",
       "      <td>0.039150</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>-0.015787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>-0.007196</td>\n",
       "      <td>-0.041652</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.047604</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.016415</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.013689</td>\n",
       "      <td>-0.037855</td>\n",
       "      <td>0.039763</td>\n",
       "      <td>0.035750</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>-0.050556</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>-0.048696</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.036328</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>-0.021304</td>\n",
       "      <td>-0.032017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    0.009625 -0.029216  0.027109  0.023631 -0.004972  0.031757 -0.045125   \n",
       "1   -0.007535 -0.039844  0.030167  0.031224  0.004742  0.028289 -0.068723   \n",
       "2    0.022408 -0.030840  0.032328  0.046965  0.007798  0.025860 -0.065093   \n",
       "3    0.019677 -0.034055  0.012662  0.070387 -0.011170  0.017842 -0.050945   \n",
       "4    0.017678 -0.030323  0.012829  0.065267 -0.025161  0.011964 -0.050590   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "895  0.019743 -0.071799  0.022546  0.049042 -0.005767 -0.016275 -0.037731   \n",
       "896  0.000186 -0.027604  0.010623  0.038237 -0.026675  0.020215 -0.040816   \n",
       "897  0.018066 -0.032152  0.039794  0.047608  0.003898  0.024092 -0.056508   \n",
       "898 -0.003492 -0.022739  0.021777  0.044054 -0.005621  0.013863 -0.079196   \n",
       "899  0.013689 -0.037855  0.039763  0.035750  0.004115  0.005637 -0.050556   \n",
       "\n",
       "      embed_7   embed_8   embed_9  ...  embed_759  embed_760  embed_761  \\\n",
       "0    0.044483  0.019400 -0.017189  ...  -0.001972  -0.008154  -0.056139   \n",
       "1    0.039153  0.019596 -0.027138  ...   0.008613  -0.006578  -0.034220   \n",
       "2    0.035118  0.035359 -0.029205  ...   0.020413  -0.034288  -0.050649   \n",
       "3    0.044878  0.034781 -0.025772  ...   0.002963  -0.018754  -0.053278   \n",
       "4    0.042820  0.029161 -0.015004  ...   0.010192  -0.010147  -0.035857   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "895  0.029718  0.009203 -0.030913  ...  -0.001192  -0.026138  -0.056447   \n",
       "896  0.032210  0.041016 -0.014836  ...   0.015479  -0.003967  -0.037808   \n",
       "897  0.020527  0.031972 -0.026038  ...   0.011308  -0.016882  -0.059904   \n",
       "898  0.039150  0.004557 -0.015787  ...   0.004005  -0.007196  -0.041652   \n",
       "899  0.024668  0.025077 -0.029114  ...  -0.000129  -0.003880  -0.048696   \n",
       "\n",
       "     embed_762  embed_763  embed_764  embed_765  embed_766  embed_767  Label  \n",
       "0     0.009890   0.042366   0.040134   0.009304  -0.016137  -0.009309      0  \n",
       "1     0.027574   0.045456   0.027402   0.017837  -0.035009  -0.010062      0  \n",
       "2     0.028408   0.040412   0.030261   0.003535  -0.034122  -0.017289      0  \n",
       "3     0.033005   0.031635   0.022544  -0.011774  -0.011125  -0.017540      0  \n",
       "4     0.021784   0.034621   0.017342  -0.009884  -0.010316  -0.029238      0  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "895   0.015818   0.045241   0.012620  -0.004837  -0.014540  -0.046791      2  \n",
       "896   0.021234   0.031012  -0.010890   0.003081  -0.015145  -0.045444      0  \n",
       "897   0.009558   0.039976   0.029574   0.013737  -0.003724  -0.017324      2  \n",
       "898   0.020945   0.047604   0.019767   0.005806  -0.019280  -0.016415      5  \n",
       "899   0.015711   0.039773   0.036328   0.010483  -0.021304  -0.032017      2  \n",
       "\n",
       "[900 rows x 769 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "df=pd.read_excel('embeddingsdata.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d6c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X =df.iloc[:,0:768]\n",
    "y=df.iloc[:,768]\n",
    "y_binary = (y > 2).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8cb271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors: 362\n",
      "Support vectors:\n",
      " [[ 0.015554   -0.01554439  0.02790753 ...  0.01496033 -0.02077759\n",
      "  -0.02452972]\n",
      " [ 0.02497271 -0.02393755  0.0139915  ...  0.01697529 -0.01942221\n",
      "  -0.01307276]\n",
      " [-0.01310535 -0.04361204  0.04274568 ...  0.01442266 -0.00612459\n",
      "  -0.02965391]\n",
      " ...\n",
      " [ 0.01862932 -0.03572857  0.03910579 ... -0.00278428 -0.01012257\n",
      "  -0.00942968]\n",
      " [ 0.0057842  -0.03262983  0.01674824 ...  0.00469324 -0.02775218\n",
      "  -0.02564372]\n",
      " [-0.00771731 -0.01470342  0.02145738 ...  0.00274074 -0.00652491\n",
      "  -0.00409873]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "clf = svm.SVC()\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "# Get the support vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "# Study the support vectors\n",
    "print(\"Number of support vectors:\", len(support_vectors))\n",
    "print(\"Support vectors:\\n\", support_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6136391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.7733333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create an instance of the SVM classifier\n",
    "clf = svm.SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the accuracy of the SVM using the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy on the test set:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b73a65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sreenath\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing both features and labels\n",
    "X = df.iloc[:, 0:768]\n",
    "y = df.iloc[:, 768]\n",
    "y_binary = (y > 2).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Now, you can predict the class for a new sample\n",
    "# For example, using the first sample from the test set\n",
    "test_sample = X_test.iloc[7, :].values.reshape(1, -1)\n",
    "predicted_class = clf.predict(test_sample)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43edb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 - Actual: 0, Predicted: 0\n",
      "Sample 2 - Actual: 0, Predicted: 0\n",
      "Sample 3 - Actual: 0, Predicted: 0\n",
      "Sample 4 - Actual: 0, Predicted: 0\n",
      "Sample 5 - Actual: 0, Predicted: 0\n",
      "Sample 6 - Actual: 0, Predicted: 0\n",
      "Sample 7 - Actual: 0, Predicted: 0\n",
      "Sample 8 - Actual: 0, Predicted: 0\n",
      "Sample 9 - Actual: 0, Predicted: 0\n",
      "Sample 10 - Actual: 0, Predicted: 0\n",
      "Sample 11 - Actual: 0, Predicted: 0\n",
      "Sample 12 - Actual: 1, Predicted: 0\n",
      "Sample 13 - Actual: 0, Predicted: 0\n",
      "Sample 14 - Actual: 0, Predicted: 0\n",
      "Sample 15 - Actual: 0, Predicted: 0\n",
      "Sample 16 - Actual: 0, Predicted: 0\n",
      "Sample 17 - Actual: 0, Predicted: 0\n",
      "Sample 18 - Actual: 0, Predicted: 0\n",
      "Sample 19 - Actual: 1, Predicted: 0\n",
      "Sample 20 - Actual: 0, Predicted: 0\n",
      "Sample 21 - Actual: 0, Predicted: 0\n",
      "Sample 22 - Actual: 0, Predicted: 0\n",
      "Sample 23 - Actual: 0, Predicted: 0\n",
      "Sample 24 - Actual: 1, Predicted: 0\n",
      "Sample 25 - Actual: 1, Predicted: 0\n",
      "Sample 26 - Actual: 0, Predicted: 0\n",
      "Sample 27 - Actual: 0, Predicted: 0\n",
      "Sample 28 - Actual: 0, Predicted: 0\n",
      "Sample 29 - Actual: 0, Predicted: 0\n",
      "Sample 30 - Actual: 1, Predicted: 0\n",
      "Sample 31 - Actual: 1, Predicted: 0\n",
      "Sample 32 - Actual: 0, Predicted: 0\n",
      "Sample 33 - Actual: 0, Predicted: 0\n",
      "Sample 34 - Actual: 1, Predicted: 0\n",
      "Sample 35 - Actual: 0, Predicted: 0\n",
      "Sample 36 - Actual: 0, Predicted: 0\n",
      "Sample 37 - Actual: 0, Predicted: 0\n",
      "Sample 38 - Actual: 0, Predicted: 0\n",
      "Sample 39 - Actual: 0, Predicted: 0\n",
      "Sample 40 - Actual: 0, Predicted: 0\n",
      "Sample 41 - Actual: 0, Predicted: 0\n",
      "Sample 42 - Actual: 0, Predicted: 0\n",
      "Sample 43 - Actual: 0, Predicted: 0\n",
      "Sample 44 - Actual: 0, Predicted: 0\n",
      "Sample 45 - Actual: 0, Predicted: 0\n",
      "Sample 46 - Actual: 0, Predicted: 0\n",
      "Sample 47 - Actual: 0, Predicted: 0\n",
      "Sample 48 - Actual: 0, Predicted: 0\n",
      "Sample 49 - Actual: 1, Predicted: 0\n",
      "Sample 50 - Actual: 0, Predicted: 0\n",
      "Sample 51 - Actual: 1, Predicted: 0\n",
      "Sample 52 - Actual: 0, Predicted: 0\n",
      "Sample 53 - Actual: 0, Predicted: 0\n",
      "Sample 54 - Actual: 0, Predicted: 0\n",
      "Sample 55 - Actual: 0, Predicted: 0\n",
      "Sample 56 - Actual: 0, Predicted: 0\n",
      "Sample 57 - Actual: 0, Predicted: 0\n",
      "Sample 58 - Actual: 1, Predicted: 0\n",
      "Sample 59 - Actual: 0, Predicted: 0\n",
      "Sample 60 - Actual: 1, Predicted: 0\n",
      "Sample 61 - Actual: 0, Predicted: 0\n",
      "Sample 62 - Actual: 1, Predicted: 0\n",
      "Sample 63 - Actual: 0, Predicted: 0\n",
      "Sample 64 - Actual: 1, Predicted: 0\n",
      "Sample 65 - Actual: 0, Predicted: 0\n",
      "Sample 66 - Actual: 0, Predicted: 0\n",
      "Sample 67 - Actual: 0, Predicted: 0\n",
      "Sample 68 - Actual: 1, Predicted: 0\n",
      "Sample 69 - Actual: 0, Predicted: 0\n",
      "Sample 70 - Actual: 1, Predicted: 0\n",
      "Sample 71 - Actual: 0, Predicted: 0\n",
      "Sample 72 - Actual: 1, Predicted: 0\n",
      "Sample 73 - Actual: 0, Predicted: 0\n",
      "Sample 74 - Actual: 0, Predicted: 0\n",
      "Sample 75 - Actual: 0, Predicted: 0\n",
      "Sample 76 - Actual: 0, Predicted: 0\n",
      "Sample 77 - Actual: 1, Predicted: 0\n",
      "Sample 78 - Actual: 0, Predicted: 0\n",
      "Sample 79 - Actual: 0, Predicted: 0\n",
      "Sample 80 - Actual: 1, Predicted: 0\n",
      "Sample 81 - Actual: 1, Predicted: 0\n",
      "Sample 82 - Actual: 0, Predicted: 0\n",
      "Sample 83 - Actual: 0, Predicted: 0\n",
      "Sample 84 - Actual: 0, Predicted: 0\n",
      "Sample 85 - Actual: 0, Predicted: 0\n",
      "Sample 86 - Actual: 0, Predicted: 0\n",
      "Sample 87 - Actual: 0, Predicted: 0\n",
      "Sample 88 - Actual: 0, Predicted: 0\n",
      "Sample 89 - Actual: 0, Predicted: 0\n",
      "Sample 90 - Actual: 1, Predicted: 0\n",
      "Sample 91 - Actual: 0, Predicted: 0\n",
      "Sample 92 - Actual: 0, Predicted: 0\n",
      "Sample 93 - Actual: 1, Predicted: 0\n",
      "Sample 94 - Actual: 0, Predicted: 0\n",
      "Sample 95 - Actual: 0, Predicted: 0\n",
      "Sample 96 - Actual: 0, Predicted: 0\n",
      "Sample 97 - Actual: 0, Predicted: 0\n",
      "Sample 98 - Actual: 0, Predicted: 0\n",
      "Sample 99 - Actual: 0, Predicted: 0\n",
      "Sample 100 - Actual: 0, Predicted: 0\n",
      "Sample 101 - Actual: 1, Predicted: 0\n",
      "Sample 102 - Actual: 0, Predicted: 0\n",
      "Sample 103 - Actual: 0, Predicted: 0\n",
      "Sample 104 - Actual: 0, Predicted: 0\n",
      "Sample 105 - Actual: 0, Predicted: 0\n",
      "Sample 106 - Actual: 0, Predicted: 0\n",
      "Sample 107 - Actual: 0, Predicted: 0\n",
      "Sample 108 - Actual: 0, Predicted: 0\n",
      "Sample 109 - Actual: 0, Predicted: 0\n",
      "Sample 110 - Actual: 0, Predicted: 0\n",
      "Sample 111 - Actual: 0, Predicted: 0\n",
      "Sample 112 - Actual: 0, Predicted: 0\n",
      "Sample 113 - Actual: 0, Predicted: 0\n",
      "Sample 114 - Actual: 1, Predicted: 0\n",
      "Sample 115 - Actual: 1, Predicted: 0\n",
      "Sample 116 - Actual: 1, Predicted: 0\n",
      "Sample 117 - Actual: 0, Predicted: 0\n",
      "Sample 118 - Actual: 0, Predicted: 0\n",
      "Sample 119 - Actual: 0, Predicted: 0\n",
      "Sample 120 - Actual: 1, Predicted: 0\n",
      "Sample 121 - Actual: 0, Predicted: 0\n",
      "Sample 122 - Actual: 0, Predicted: 0\n",
      "Sample 123 - Actual: 0, Predicted: 0\n",
      "Sample 124 - Actual: 0, Predicted: 0\n",
      "Sample 125 - Actual: 0, Predicted: 0\n",
      "Sample 126 - Actual: 0, Predicted: 0\n",
      "Sample 127 - Actual: 1, Predicted: 0\n",
      "Sample 128 - Actual: 0, Predicted: 0\n",
      "Sample 129 - Actual: 0, Predicted: 0\n",
      "Sample 130 - Actual: 0, Predicted: 0\n",
      "Sample 131 - Actual: 0, Predicted: 0\n",
      "Sample 132 - Actual: 0, Predicted: 0\n",
      "Sample 133 - Actual: 0, Predicted: 0\n",
      "Sample 134 - Actual: 0, Predicted: 0\n",
      "Sample 135 - Actual: 0, Predicted: 0\n",
      "Sample 136 - Actual: 0, Predicted: 0\n",
      "Sample 137 - Actual: 0, Predicted: 0\n",
      "Sample 138 - Actual: 0, Predicted: 0\n",
      "Sample 139 - Actual: 0, Predicted: 0\n",
      "Sample 140 - Actual: 0, Predicted: 0\n",
      "Sample 141 - Actual: 0, Predicted: 0\n",
      "Sample 142 - Actual: 1, Predicted: 0\n",
      "Sample 143 - Actual: 0, Predicted: 0\n",
      "Sample 144 - Actual: 0, Predicted: 0\n",
      "Sample 145 - Actual: 0, Predicted: 0\n",
      "Sample 146 - Actual: 0, Predicted: 0\n",
      "Sample 147 - Actual: 1, Predicted: 0\n",
      "Sample 148 - Actual: 0, Predicted: 0\n",
      "Sample 149 - Actual: 0, Predicted: 0\n",
      "Sample 150 - Actual: 0, Predicted: 0\n",
      "Sample 151 - Actual: 0, Predicted: 0\n",
      "Sample 152 - Actual: 0, Predicted: 0\n",
      "Sample 153 - Actual: 0, Predicted: 0\n",
      "Sample 154 - Actual: 1, Predicted: 0\n",
      "Sample 155 - Actual: 0, Predicted: 0\n",
      "Sample 156 - Actual: 0, Predicted: 0\n",
      "Sample 157 - Actual: 0, Predicted: 0\n",
      "Sample 158 - Actual: 1, Predicted: 0\n",
      "Sample 159 - Actual: 0, Predicted: 0\n",
      "Sample 160 - Actual: 0, Predicted: 0\n",
      "Sample 161 - Actual: 0, Predicted: 0\n",
      "Sample 162 - Actual: 0, Predicted: 0\n",
      "Sample 163 - Actual: 0, Predicted: 0\n",
      "Sample 164 - Actual: 0, Predicted: 0\n",
      "Sample 165 - Actual: 0, Predicted: 0\n",
      "Sample 166 - Actual: 1, Predicted: 0\n",
      "Sample 167 - Actual: 0, Predicted: 0\n",
      "Sample 168 - Actual: 0, Predicted: 0\n",
      "Sample 169 - Actual: 1, Predicted: 0\n",
      "Sample 170 - Actual: 1, Predicted: 0\n",
      "Sample 171 - Actual: 0, Predicted: 0\n",
      "Sample 172 - Actual: 0, Predicted: 0\n",
      "Sample 173 - Actual: 0, Predicted: 0\n",
      "Sample 174 - Actual: 1, Predicted: 0\n",
      "Sample 175 - Actual: 1, Predicted: 0\n",
      "Sample 176 - Actual: 0, Predicted: 0\n",
      "Sample 177 - Actual: 1, Predicted: 0\n",
      "Sample 178 - Actual: 0, Predicted: 0\n",
      "Sample 179 - Actual: 0, Predicted: 0\n",
      "Sample 180 - Actual: 0, Predicted: 0\n",
      "\n",
      "Accuracy: 79.44%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X = df.iloc[:, 0:768]\n",
    "y = df.iloc[:, 768]\n",
    "y_binary = (y > 2).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predicted_labels = clf.predict(X_test)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"Sample {i + 1} - Actual: {y_test.iloc[i]}, Predicted: {predicted_labels[i]}\")\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e83faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with linear kernel: 79.44%\n",
      "Accuracy with poly kernel: 79.44%\n",
      "Accuracy with rbf kernel: 79.44%\n",
      "Accuracy with sigmoid kernel: 79.44%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.iloc[:, 0:768]\n",
    "y = df.iloc[:, 768]\n",
    "y_binary = (y > 2).astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "kernel_functions = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernel_functions:\n",
    "\n",
    "    clf = SVC(kernel=kernel)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    predicted_labels = clf.predict(X_test)\n",
    "\n",
    "    # Calculate and print the accuracy for each kernel\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    print(f\"Accuracy with {kernel} kernel: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68203c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
